---
title: 文本预处理
---

# 文本预处理

> 掌握文本清洗和标准化技术

## 📚 学习目标

- 掌握文本清洗方法
- 学会去除停用词
- 理解词干提取和词形还原
- 掌握文本标准化

## 1. 文本清洗

```python
import re

def clean_text(text):
    # 转小写
    text = text.lower()
    
    # 去除URL
    text = re.sub(r'http\S+|www.\S+', '', text)
    
    # 去除HTML标签
    text = re.sub(r'<.*?>', '', text)
    
    # 去除邮箱
    text = re.sub(r'\S+@\S+', '', text)
    
    # 去除特殊字符（保留中英文和数字）
    text = re.sub(r'[^\w\s\u4e00-\u9fff]', '', text)
    
    # 去除多余空格
    text = ' '.join(text.split())
    
    return text

# 示例
text = "访问 https://example.com 查看详情！！！"
print(clean_text(text))
```

## 2. 去除停用词

```python
import jieba

# 中文停用词
def load_stopwords(file_path='stopwords.txt'):
    with open(file_path, 'r', encoding='utf-8') as f:
        return set([line.strip() for line in f])

def remove_stopwords(text, stopwords):
    words = jieba.cut(text)
    return [w for w in words if w not in stopwords and len(w) > 1]

# 英文停用词
from nltk.corpus import stopwords

stop_words = set(stopwords.words('english'))
text = "This is a sample sentence"
words = [w for w in text.split() if w.lower() not in stop_words]
```

## 3. 词干提取和词形还原

```python
from nltk.stem import PorterStemmer, WordNetLemmatizer

# 词干提取
stemmer = PorterStemmer()
words = ["running", "runs", "ran", "runner"]
stems = [stemmer.stem(w) for w in words]
print(stems)  # ['run', 'run', 'ran', 'runner']

# 词形还原
lemmatizer = WordNetLemmatizer()
lemmas = [lemmatizer.lemmatize(w, pos='v') for w in words]
print(lemmas)  # ['run', 'run', 'run', 'runner']
```

## 4. 文本标准化

```python
# 繁简转换
from opencc import OpenCC

cc = OpenCC('t2s')  # 繁体转简体
text = "繁體中文"
print(cc.convert(text))  # 简体中文

# 全角半角转换
def strQ2B(text):
    rstring = ""
    for char in text:
        code = ord(char)
        if code == 0x3000:
            code = 0x0020
        else:
            code -= 0xfee0
        if not (0x0021 <= code <= 0x7e):
            rstring += char
            continue
        rstring += chr(code)
    return rstring
```

---

**下一节：** [中文分词](03-中文分词.md)
