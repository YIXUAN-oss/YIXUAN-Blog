---
title: 实战案例
---

# 实战案例

> 通过实战项目巩固NumPy知识

## 📚 学习目标

- 应用NumPy解决实际问题
- 掌握数据处理技巧
- 学会性能优化
- 综合运用所学知识

## 1. 图像处理

### 案例1：图像灰度化

```python
import numpy as np

# 模拟彩色图像（RGB）
height, width = 100, 100
image_rgb = np.random.randint(0, 256, (height, width, 3), dtype=np.uint8)

# 灰度化公式：Gray = 0.299*R + 0.587*G + 0.114*B
weights = np.array([0.299, 0.587, 0.114])
image_gray = np.dot(image_rgb, weights).astype(np.uint8)

print(f'彩色图像形状: {image_rgb.shape}')
print(f'灰度图像形状: {image_gray.shape}')
```

### 案例2：图像滤波

```python
# 均值滤波（3x3）
def mean_filter(image):
    h, w = image.shape
    filtered = np.zeros_like(image)
    
    for i in range(1, h-1):
        for j in range(1, w-1):
            filtered[i, j] = np.mean(image[i-1:i+2, j-1:j+2])
    
    return filtered

# 使用卷积实现（更快）
def mean_filter_fast(image):
    from scipy.ndimage import convolve
    kernel = np.ones((3, 3)) / 9
    return convolve(image, kernel)
```

## 2. 数据分析

### 案例1：学生成绩分析

```python
# 生成学生成绩数据
np.random.seed(42)
students = 100
subjects = 5

scores = np.random.normal(75, 10, (students, subjects))
scores = np.clip(scores, 0, 100)  # 限制在0-100

# 统计分析
print('=== 成绩统计 ===')
print(f'平均分: {scores.mean():.2f}')
print(f'最高分: {scores.max():.2f}')
print(f'最低分: {scores.min():.2f}')
print(f'标准差: {scores.std():.2f}')

# 各科平均分
subject_means = scores.mean(axis=0)
for i, mean in enumerate(subject_means, 1):
    print(f'科目{i}平均分: {mean:.2f}')

# 每个学生的总分和平均分
total_scores = scores.sum(axis=1)
student_means = scores.mean(axis=1)

# 排名
rankings = np.argsort(total_scores)[::-1]
print(f'\n前5名学生: {rankings[:5]}')
print(f'前5名总分: {total_scores[rankings[:5]]}')

# 分数段统计
bins = [0, 60, 70, 80, 90, 100]
labels = ['不及格', '及格', '中等', '良好', '优秀']

for i in range(subjects):
    hist, _ = np.histogram(scores[:, i], bins=bins)
    print(f'\n科目{i+1}分数段分布:')
    for label, count in zip(labels, hist):
        print(f'  {label}: {count}人 ({count/students*100:.1f}%)')
```

### 案例2：时间序列分析

```python
# 生成股票价格数据
np.random.seed(42)
days = 252  # 一年交易日
start_price = 100

# 模拟随机游走
returns = np.random.normal(0.001, 0.02, days)
prices = start_price * np.exp(np.cumsum(returns))

# 计算移动平均
def moving_average(data, window):
    weights = np.ones(window) / window
    return np.convolve(data, weights, mode='valid')

ma5 = moving_average(prices, 5)
ma20 = moving_average(prices, 20)

# 计算波动率
def volatility(prices, window=20):
    returns = np.diff(np.log(prices))
    vol = np.zeros(len(prices))
    for i in range(window, len(prices)):
        vol[i] = np.std(returns[i-window:i]) * np.sqrt(252)
    return vol

vol = volatility(prices)

print(f'期初价格: {prices[0]:.2f}')
print(f'期末价格: {prices[-1]:.2f}')
print(f'收益率: {(prices[-1]/prices[0] - 1)*100:.2f}%')
print(f'最大回撤: {((prices.max() - prices.min())/prices.max())*100:.2f}%')
```

## 3. 机器学习预处理

### 案例1：数据标准化

```python
# 生成数据
data = np.random.randn(1000, 10) * 100 + 50

# Z-score标准化
def z_score_normalize(data):
    mean = data.mean(axis=0)
    std = data.std(axis=0)
    return (data - mean) / std

# Min-Max归一化
def min_max_normalize(data):
    min_val = data.min(axis=0)
    max_val = data.max(axis=0)
    return (data - min_val) / (max_val - min_val)

# L2归一化
def l2_normalize(data):
    norms = np.linalg.norm(data, axis=1, keepdims=True)
    return data / norms

data_zscore = z_score_normalize(data)
data_minmax = min_max_normalize(data)
data_l2 = l2_normalize(data)

print('原始数据范围:', data.min(), '~', data.max())
print('Z-score后范围:', data_zscore.min(), '~', data_zscore.max())
print('Min-Max后范围:', data_minmax.min(), '~', data_minmax.max())
```

### 案例2：特征工程

```python
# 多项式特征
def polynomial_features(X, degree=2):
    """生成多项式特征"""
    n_samples, n_features = X.shape
    features = [X]
    
    for d in range(2, degree + 1):
        features.append(X ** d)
    
    return np.hstack(features)

X = np.array([[1, 2], [3, 4], [5, 6]])
X_poly = polynomial_features(X, degree=2)
print('原始特征:\n', X)
print('多项式特征:\n', X_poly)

# 特征选择（方差过滤）
def variance_threshold(X, threshold=0.0):
    """移除低方差特征"""
    variances = X.var(axis=0)
    return X[:, variances > threshold]
```

## 4. 数值计算

### 案例1：矩阵运算优化

```python
import time

n = 1000

# 方式1：使用循环（慢）
A = np.random.rand(n, n)
B = np.random.rand(n, n)

start = time.time()
C = np.zeros((n, n))
for i in range(n):
    for j in range(n):
        for k in range(n):
            C[i, j] += A[i, k] * B[k, j]
loop_time = time.time() - start

# 方式2：使用NumPy（快）
start = time.time()
C = A @ B
numpy_time = time.time() - start

print(f'循环耗时: {loop_time:.4f}秒')
print(f'NumPy耗时: {numpy_time:.4f}秒')
print(f'加速比: {loop_time/numpy_time:.1f}x')
```

### 案例2：求解最小二乘问题

```python
# 线性回归：y = ax + b
np.random.seed(42)
x = np.linspace(0, 10, 100)
y = 2 * x + 1 + np.random.randn(100) * 2

# 构造设计矩阵
X = np.vstack([x, np.ones(len(x))]).T

# 求解最小二乘
params = np.linalg.lstsq(X, y, rcond=None)[0]
a, b = params

print(f'拟合结果: y = {a:.2f}x + {b:.2f}')

# 计算R²
y_pred = a * x + b
ss_res = np.sum((y - y_pred) ** 2)
ss_tot = np.sum((y - y.mean()) ** 2)
r2 = 1 - ss_res / ss_tot
print(f'R²: {r2:.4f}')
```

## 5. 算法实现

### 案例1：K-means聚类

```python
def kmeans(X, k, max_iters=100):
    """简单的K-means实现"""
    n_samples = X.shape[0]
    
    # 随机初始化中心点
    indices = np.random.choice(n_samples, k, replace=False)
    centers = X[indices]
    
    for _ in range(max_iters):
        # 分配样本到最近的中心
        distances = np.sqrt(((X - centers[:, np.newaxis])**2).sum(axis=2))
        labels = np.argmin(distances, axis=0)
        
        # 更新中心点
        new_centers = np.array([X[labels == i].mean(axis=0) for i in range(k)])
        
        # 检查收敛
        if np.allclose(centers, new_centers):
            break
        
        centers = new_centers
    
    return labels, centers

# 测试
np.random.seed(42)
X = np.vstack([
    np.random.randn(100, 2) + [2, 2],
    np.random.randn(100, 2) + [-2, -2],
    np.random.randn(100, 2) + [2, -2]
])

labels, centers = kmeans(X, k=3)
print('聚类中心:\n', centers)
```

### 案例2：梯度下降

```python
def gradient_descent(X, y, learning_rate=0.01, epochs=1000):
    """线性回归的梯度下降"""
    n_samples, n_features = X.shape
    weights = np.zeros(n_features)
    bias = 0
    
    for epoch in range(epochs):
        # 前向传播
        y_pred = X @ weights + bias
        
        # 计算梯度
        dw = (1/n_samples) * X.T @ (y_pred - y)
        db = (1/n_samples) * np.sum(y_pred - y)
        
        # 更新参数
        weights -= learning_rate * dw
        bias -= learning_rate * db
        
        # 每100轮打印损失
        if epoch % 100 == 0:
            loss = np.mean((y_pred - y) ** 2)
            print(f'Epoch {epoch}, Loss: {loss:.4f}')
    
    return weights, bias

# 测试
np.random.seed(42)
X = np.random.randn(100, 3)
true_weights = np.array([1, 2, 3])
y = X @ true_weights + np.random.randn(100) * 0.1

weights, bias = gradient_descent(X, y)
print('真实权重:', true_weights)
print('学习权重:', weights)
```

## 6. 性能优化总结

```python
# 1. 使用向量化操作
arr = np.random.rand(1000)

# ❌ 慢
result = np.array([x**2 for x in arr])

# ✅ 快
result = arr ** 2

# 2. 避免不必要的复制
arr = np.random.rand(1000, 1000)

# ❌ 创建副本
arr_copy = arr.copy()

# ✅ 使用视图
arr_view = arr[:]

# 3. 使用合适的数据类型
# ❌ 使用float64（8字节）
arr_float64 = np.random.rand(1000000)

# ✅ 使用float32（4字节）
arr_float32 = np.random.rand(1000000).astype(np.float32)

print(f'float64内存: {arr_float64.nbytes / 1024 / 1024:.2f}MB')
print(f'float32内存: {arr_float32.nbytes / 1024 / 1024:.2f}MB')

# 4. 预分配数组
# ❌ 动态增长
result = np.array([])
for i in range(1000):
    result = np.append(result, i)

# ✅ 预分配
result = np.zeros(1000)
for i in range(1000):
    result[i] = i
```

## 💡 总结

通过这些实战案例，我们学习了：

1. **图像处理** - 灰度化、滤波
2. **数据分析** - 统计分析、时间序列
3. **机器学习** - 数据预处理、特征工程
4. **数值计算** - 矩阵运算、优化算法
5. **算法实现** - K-means、梯度下降
6. **性能优化** - 向量化、内存管理

## 练习项目

1. 实现图像的边缘检测（Sobel算子）
2. 编写一个简单的推荐系统（协同过滤）
3. 实现PCA降维算法
4. 开发一个数据清洗工具

---

**恭喜完成 NumPy 教程！** 🎉

继续学习：[Pandas 数据分析](../pandas/)
