---
title: 线性代数
---

# 线性代数

> 使用NumPy进行线性代数运算

## 📚 学习目标

- 掌握矩阵运算
- 理解矩阵分解
- 学会解线性方程组
- 掌握特征值和特征向量

## 1. 矩阵乘法

```python
import numpy as np

A = np.array([[1, 2], [3, 4]])
B = np.array([[5, 6], [7, 8]])

# 矩阵乘法（dot）
C = np.dot(A, B)
print(C)

# @ 运算符（Python 3.5+）
C = A @ B
print(C)

# 逐元素乘法
element_wise = A * B
print(element_wise)

# 向量点积
a = np.array([1, 2, 3])
b = np.array([4, 5, 6])
print(np.dot(a, b))  # 32
```

## 2. 矩阵基本操作

```python
A = np.array([[1, 2], [3, 4]])

# 转置
print(A.T)

# 逆矩阵
A_inv = np.linalg.inv(A)
print(A_inv)

# 验证：A × A^(-1) = I
I = A @ A_inv
print(np.round(I))

# 行列式
det = np.linalg.det(A)
print(f'行列式: {det}')

# 矩阵的秩
rank = np.linalg.matrix_rank(A)
print(f'秩: {rank}')

# 迹（对角线元素之和）
trace = np.trace(A)
print(f'迹: {trace}')
```

## 3. 解线性方程组

```python
# Ax = b
A = np.array([[3, 1], [1, 2]])
b = np.array([9, 8])

# 求解
x = np.linalg.solve(A, b)
print(f'解: {x}')  # [2. 3.]

# 验证
print(A @ x)  # [9. 8.]

# 最小二乘解（超定系统）
A = np.array([[1, 1], [1, 2], [1, 3]])
b = np.array([1, 2, 2])
x, residuals, rank, s = np.linalg.lstsq(A, b, rcond=None)
print(f'最小二乘解: {x}')
```

## 4. 特征值和特征向量

```python
A = np.array([[1, 2], [2, 1]])

# 计算特征值和特征向量
eigenvalues, eigenvectors = np.linalg.eig(A)

print('特征值:', eigenvalues)
print('特征向量:\n', eigenvectors)

# 验证：A × v = λ × v
for i in range(len(eigenvalues)):
    λ = eigenvalues[i]
    v = eigenvectors[:, i]
    print(f'\nA × v = {A @ v}')
    print(f'λ × v = {λ * v}')
```

## 5. 矩阵分解

### 5.1 QR分解

```python
A = np.array([[1, 2], [3, 4], [5, 6]])

Q, R = np.linalg.qr(A)
print('Q (正交矩阵):\n', Q)
print('R (上三角矩阵):\n', R)

# 验证
print('Q × R =\n', Q @ R)
```

### 5.2 SVD分解

```python
A = np.array([[1, 2], [3, 4], [5, 6]])

U, s, Vt = np.linalg.svd(A)
print('U:', U.shape)
print('奇异值:', s)
print('V^T:', Vt.shape)

# 重构矩阵
S = np.zeros((U.shape[1], Vt.shape[0]))
S[:len(s), :len(s)] = np.diag(s)
A_reconstructed = U @ S @ Vt
print('重构矩阵:\n', A_reconstructed)
```

### 5.3 Cholesky分解

```python
# 正定矩阵的Cholesky分解
A = np.array([[4, 2], [2, 3]])

L = np.linalg.cholesky(A)
print('L (下三角):\n', L)

# 验证：A = L × L^T
print('L × L^T =\n', L @ L.T)
```

## 6. 范数

```python
v = np.array([3, 4])

# 向量范数
print('L1范数:', np.linalg.norm(v, 1))  # 7
print('L2范数:', np.linalg.norm(v, 2))  # 5.0
print('无穷范数:', np.linalg.norm(v, np.inf))  # 4

# 矩阵范数
A = np.array([[1, 2], [3, 4]])
print('Frobenius范数:', np.linalg.norm(A, 'fro'))
```

## 7. 实战应用

### PCA主成分分析

```python
# 生成数据
np.random.seed(42)
data = np.random.randn(100, 5)

# 中心化
data_centered = data - data.mean(axis=0)

# 计算协方差矩阵
cov_matrix = np.cov(data_centered.T)

# 特征值分解
eigenvalues, eigenvectors = np.linalg.eig(cov_matrix)

# 选择前2个主成分
idx = eigenvalues.argsort()[::-1]
top_eigenvectors = eigenvectors[:, idx[:2]]

# 降维
data_pca = data_centered @ top_eigenvectors
print(f'降维后形状: {data_pca.shape}')  # (100, 2)
```

## 练习题

1. 计算3x3矩阵的逆矩阵
2. 解线性方程组
3. 计算矩阵的特征值

---

**下一节：** [统计函数](08-统计函数.md)
