---
title: 多线程与多进程
---

# 多线程与多进程

> 掌握Python并发编程，提升程序性能

## 📚 学习目标

- 理解线程和进程的区别
- 掌握 threading 模块
- 掌握 multiprocessing 模块
- 学会使用线程池和进程池
- 理解 GIL 的影响

## 1. 线程基础

### 1.1 创建线程

```python
import threading
import time

def worker(name):
    print(f'线程 {name} 开始')
    time.sleep(2)
    print(f'线程 {name} 结束')

# 创建线程
t = threading.Thread(target=worker, args=('A',))
t.start()  # 启动线程
t.join()   # 等待线程结束

print('主线程结束')
```

### 1.2 继承 Thread 类

```python
class MyThread(threading.Thread):
    def __init__(self, name):
        super().__init__()
        self.name = name
    
    def run(self):
        print(f'{self.name} 开始执行')
        time.sleep(1)
        print(f'{self.name} 执行完成')

# 使用
t = MyThread('Worker-1')
t.start()
t.join()
```

### 1.3 多个线程

```python
import threading

def print_numbers():
    for i in range(5):
        print(f'数字: {i}')
        time.sleep(0.1)

def print_letters():
    for letter in 'ABCDE':
        print(f'字母: {letter}')
        time.sleep(0.1)

# 创建多个线程
t1 = threading.Thread(target=print_numbers)
t2 = threading.Thread(target=print_letters)

t1.start()
t2.start()

t1.join()
t2.join()
```

## 2. 线程同步

### 2.1 Lock 锁

```python
import threading

counter = 0
lock = threading.Lock()

def increment():
    global counter
    for _ in range(100000):
        lock.acquire()
        try:
            counter += 1
        finally:
            lock.release()

# 或使用 with 语句
def increment_with():
    global counter
    for _ in range(100000):
        with lock:
            counter += 1

threads = [threading.Thread(target=increment) for _ in range(10)]

for t in threads:
    t.start()

for t in threads:
    t.join()

print(f'Counter: {counter}')
```

### 2.2 RLock 可重入锁

```python
import threading

rlock = threading.RLock()

def recursive_function(n):
    with rlock:
        if n > 0:
            print(n)
            recursive_function(n - 1)

t = threading.Thread(target=recursive_function, args=(5,))
t.start()
t.join()
```

### 2.3 Semaphore 信号量

```python
import threading

# 限制同时访问的线程数
semaphore = threading.Semaphore(3)

def access_resource(name):
    with semaphore:
        print(f'{name} 获取资源')
        time.sleep(2)
        print(f'{name} 释放资源')

threads = [threading.Thread(target=access_resource, args=(f'Thread-{i}',)) 
           for i in range(10)]

for t in threads:
    t.start()
```

### 2.4 Event 事件

```python
import threading

event = threading.Event()

def waiter():
    print('等待事件...')
    event.wait()  # 阻塞直到事件被设置
    print('事件已触发!')

def setter():
    time.sleep(2)
    print('设置事件')
    event.set()  # 触发事件

t1 = threading.Thread(target=waiter)
t2 = threading.Thread(target=setter)

t1.start()
t2.start()
```

## 3. 线程池

### 3.1 ThreadPoolExecutor

```python
from concurrent.futures import ThreadPoolExecutor
import time

def task(n):
    print(f'任务 {n} 开始')
    time.sleep(1)
    return n * n

# 创建线程池
with ThreadPoolExecutor(max_workers=5) as executor:
    # 提交任务
    futures = [executor.submit(task, i) for i in range(10)]
    
    # 获取结果
    for future in futures:
        result = future.result()
        print(f'结果: {result}')
```

### 3.2 map() 方法

```python
from concurrent.futures import ThreadPoolExecutor

def square(n):
    return n * n

with ThreadPoolExecutor(max_workers=5) as executor:
    results = executor.map(square, range(10))
    print(list(results))
```

## 4. 进程基础

### 4.1 创建进程

```python
from multiprocessing import Process
import os

def worker(name):
    print(f'进程 {name}, PID: {os.getpid()}')
    time.sleep(2)
    print(f'进程 {name} 完成')

if __name__ == '__main__':
    p = Process(target=worker, args=('Worker-1',))
    p.start()
    p.join()
    print('主进程结束')
```

### 4.2 进程池

```python
from multiprocessing import Pool

def square(n):
    return n * n

if __name__ == '__main__':
    with Pool(processes=4) as pool:
        results = pool.map(square, range(10))
        print(results)
```

### 4.3 ProcessPoolExecutor

```python
from concurrent.futures import ProcessPoolExecutor

def compute(n):
    return sum(i * i for i in range(n))

if __name__ == '__main__':
    with ProcessPoolExecutor(max_workers=4) as executor:
        results = executor.map(compute, [10**6, 10**6, 10**6])
        for result in results:
            print(result)
```

## 5. 进程间通信

### 5.1 Queue 队列

```python
from multiprocessing import Process, Queue

def producer(queue):
    for i in range(5):
        queue.put(i)
        print(f'生产: {i}')

def consumer(queue):
    while True:
        item = queue.get()
        if item is None:
            break
        print(f'消费: {item}')

if __name__ == '__main__':
    queue = Queue()
    
    p1 = Process(target=producer, args=(queue,))
    p2 = Process(target=consumer, args=(queue,))
    
    p1.start()
    p2.start()
    
    p1.join()
    queue.put(None)  # 发送结束信号
    p2.join()
```

### 5.2 Pipe 管道

```python
from multiprocessing import Process, Pipe

def sender(conn):
    conn.send(['hello', 'world'])
    conn.close()

def receiver(conn):
    data = conn.recv()
    print(f'接收到: {data}')

if __name__ == '__main__':
    parent_conn, child_conn = Pipe()
    
    p1 = Process(target=sender, args=(parent_conn,))
    p2 = Process(target=receiver, args=(child_conn,))
    
    p1.start()
    p2.start()
    
    p1.join()
    p2.join()
```

### 5.3 Manager 共享数据

```python
from multiprocessing import Process, Manager

def worker(shared_list, shared_dict):
    shared_list.append(1)
    shared_dict['key'] = 'value'

if __name__ == '__main__':
    with Manager() as manager:
        shared_list = manager.list()
        shared_dict = manager.dict()
        
        processes = [Process(target=worker, args=(shared_list, shared_dict)) 
                     for _ in range(5)]
        
        for p in processes:
            p.start()
        for p in processes:
            p.join()
        
        print(shared_list)
        print(shared_dict)
```

## 6. 线程 vs 进程

### 6.1 何时使用线程

```python
# I/O 密集型任务（网络请求、文件读写）
import threading
import requests

def download(url):
    response = requests.get(url)
    print(f'Downloaded {len(response.content)} bytes')

urls = ['https://example.com'] * 10

threads = [threading.Thread(target=download, args=(url,)) for url in urls]

for t in threads:
    t.start()
for t in threads:
    t.join()
```

### 6.2 何时使用进程

```python
# CPU 密集型任务（计算密集）
from multiprocessing import Pool

def compute_intensive(n):
    return sum(i * i for i in range(n))

if __name__ == '__main__':
    with Pool(processes=4) as pool:
        results = pool.map(compute_intensive, [10**7] * 4)
        print(sum(results))
```

## 7. 实战案例

### 案例1：多线程下载

```python
import threading
import requests

def download_file(url, filename):
    response = requests.get(url)
    with open(filename, 'wb') as f:
        f.write(response.content)
    print(f'{filename} 下载完成')

urls = {
    'file1.jpg': 'https://example.com/image1.jpg',
    'file2.jpg': 'https://example.com/image2.jpg',
}

threads = []
for filename, url in urls.items():
    t = threading.Thread(target=download_file, args=(url, filename))
    threads.append(t)
    t.start()

for t in threads:
    t.join()

print('所有文件下载完成')
```

### 案例2：生产者-消费者模式

```python
import threading
import queue
import time

def producer(q, name):
    for i in range(5):
        item = f'{name}-{i}'
        q.put(item)
        print(f'生产: {item}')
        time.sleep(0.5)

def consumer(q, name):
    while True:
        try:
            item = q.get(timeout=2)
            print(f'{name} 消费: {item}')
            q.task_done()
        except queue.Empty:
            break

q = queue.Queue()

# 创建生产者
producers = [threading.Thread(target=producer, args=(q, f'Producer-{i}')) 
             for i in range(2)]

# 创建消费者
consumers = [threading.Thread(target=consumer, args=(q, f'Consumer-{i}')) 
             for i in range(3)]

for p in producers:
    p.start()
for c in consumers:
    c.start()

for p in producers:
    p.join()
q.join()  # 等待队列为空

print('完成')
```

## 📝 练习题

1. 实现一个多线程网页爬虫
2. 使用多进程进行图像批处理
3. 创建一个线程安全的计数器类

---

**下一节：** 进入[第04章 数据结构与算法](../第04章-数据结构与算法/)
