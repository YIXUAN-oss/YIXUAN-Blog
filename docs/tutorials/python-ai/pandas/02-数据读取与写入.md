---
title: 数据读取与写入
---

# 数据读取与写入

> 掌握Pandas的数据IO操作

## 📚 学习目标

- 掌握CSV文件的读写
- 学会Excel文件操作
- 掌握JSON数据处理
- 学会数据库操作
- 了解其他格式

## 1. CSV文件

### 1.1 读取CSV

```python
import pandas as pd

# 基本读取
df = pd.read_csv('data.csv')

# 指定分隔符
df = pd.read_csv('data.txt', sep='\t')

# 指定编码
df = pd.read_csv('data.csv', encoding='utf-8')

# 指定索引列
df = pd.read_csv('data.csv', index_col=0)

# 指定列名
df = pd.read_csv('data.csv', names=['col1', 'col2', 'col3'])

# 跳过行
df = pd.read_csv('data.csv', skiprows=[0, 2])  # 跳过第1和第3行

# 只读取部分行
df = pd.read_csv('data.csv', nrows=1000)

# 指定数据类型
df = pd.read_csv('data.csv', dtype={'age': int, 'name': str})

# 处理缺失值
df = pd.read_csv('data.csv', na_values=['NA', 'null', ''])

# 解析日期
df = pd.read_csv('data.csv', parse_dates=['date_column'])
```

### 1.2 写入CSV

```python
# 基本写入
df.to_csv('output.csv')

# 不写入索引
df.to_csv('output.csv', index=False)

# 指定分隔符
df.to_csv('output.txt', sep='\t')

# 指定编码
df.to_csv('output.csv', encoding='utf-8')

# 只写入部分列
df.to_csv('output.csv', columns=['col1', 'col2'])

# 追加模式
df.to_csv('output.csv', mode='a', header=False)
```

## 2. Excel文件

### 2.1 读取Excel

```python
# 需要安装：pip install openpyxl

# 读取Excel
df = pd.read_excel('data.xlsx')

# 指定工作表
df = pd.read_excel('data.xlsx', sheet_name='Sheet1')

# 读取多个工作表
dfs = pd.read_excel('data.xlsx', sheet_name=['Sheet1', 'Sheet2'])

# 读取所有工作表
dfs = pd.read_excel('data.xlsx', sheet_name=None)

# 指定行和列
df = pd.read_excel('data.xlsx', usecols='A:C', skiprows=2)
```

### 2.2 写入Excel

```python
# 写入Excel
df.to_excel('output.xlsx', index=False)

# 写入多个工作表
with pd.ExcelWriter('output.xlsx') as writer:
    df1.to_excel(writer, sheet_name='Sheet1', index=False)
    df2.to_excel(writer, sheet_name='Sheet2', index=False)

# 追加到现有文件
with pd.ExcelWriter('output.xlsx', mode='a') as writer:
    df.to_excel(writer, sheet_name='NewSheet')
```

## 3. JSON文件

### 3.1 读取JSON

```python
# 读取JSON文件
df = pd.read_json('data.json')

# 指定方向
df = pd.read_json('data.json', orient='records')

# 从字符串读取
json_str = '{"name": "Alice", "age": 25}'
df = pd.read_json(json_str, typ='series')

# 读取嵌套JSON
df = pd.json_normalize(json_data)
```

### 3.2 写入JSON

```python
# 写入JSON文件
df.to_json('output.json')

# 指定方向
df.to_json('output.json', orient='records')

# 格式化输出
df.to_json('output.json', indent=4)

# 转换为JSON字符串
json_str = df.to_json()
```

## 4. 数据库操作

### 4.1 SQLite

```python
import sqlite3

# 连接数据库
conn = sqlite3.connect('database.db')

# 读取数据
df = pd.read_sql('SELECT * FROM table_name', conn)

# 读取查询
query = '''
SELECT name, age 
FROM users 
WHERE age > 25
'''
df = pd.read_sql(query, conn)

# 写入数据库
df.to_sql('table_name', conn, if_exists='replace', index=False)

# 关闭连接
conn.close()
```

### 4.2 MySQL

```python
# 需要安装：pip install pymysql sqlalchemy

from sqlalchemy import create_engine

# 创建引擎
engine = create_engine('mysql+pymysql://user:password@localhost/database')

# 读取数据
df = pd.read_sql('SELECT * FROM table_name', engine)

# 写入数据
df.to_sql('table_name', engine, if_exists='append', index=False)
```

## 5. 其他格式

### 5.1 HTML

```python
# 读取HTML表格
dfs = pd.read_html('data.html')

# 从URL读取
dfs = pd.read_html('https://example.com/table.html')

# 写入HTML
df.to_html('output.html', index=False)
```

### 5.2 Parquet

```python
# 需要安装：pip install pyarrow

# 读取Parquet
df = pd.read_parquet('data.parquet')

# 写入Parquet
df.to_parquet('output.parquet')
```

### 5.3 HDF5

```python
# 写入HDF5
df.to_hdf('data.h5', key='df', mode='w')

# 读取HDF5
df = pd.read_hdf('data.h5', key='df')
```

## 6. 实战示例

### 示例1：批量处理CSV文件

```python
import glob

# 读取目录下所有CSV文件
files = glob.glob('data/*.csv')

# 合并所有文件
dfs = [pd.read_csv(f) for f in files]
combined_df = pd.concat(dfs, ignore_index=True)

print(f'合并了 {len(files)} 个文件')
print(f'总行数: {len(combined_df)}')
```

### 示例2：分块读取大文件

```python
# 分块读取
chunk_size = 10000
chunks = []

for chunk in pd.read_csv('large_file.csv', chunksize=chunk_size):
    # 处理每个块
    processed = chunk[chunk['value'] > 0]
    chunks.append(processed)

# 合并结果
result = pd.concat(chunks, ignore_index=True)
```

### 示例3：数据导出报表

```python
# 创建数据
sales_data = pd.DataFrame({
    'product': ['A', 'B', 'C'],
    'sales': [100, 200, 150],
    'profit': [20, 40, 30]
})

# 导出到Excel（多个工作表）
with pd.ExcelWriter('sales_report.xlsx', engine='openpyxl') as writer:
    # 原始数据
    sales_data.to_excel(writer, sheet_name='Raw Data', index=False)
    
    # 汇总统计
    summary = sales_data.describe()
    summary.to_excel(writer, sheet_name='Summary')
    
    # 透视表
    pivot = sales_data.pivot_table(values='sales', aggfunc='sum')
    pivot.to_excel(writer, sheet_name='Pivot')
```

## 7. 性能优化

```python
# 指定数据类型减少内存
dtypes = {
    'id': 'int32',
    'value': 'float32',
    'category': 'category'
}
df = pd.read_csv('data.csv', dtype=dtypes)

# 使用category类型
df['category'] = df['category'].astype('category')

# 只读取需要的列
df = pd.read_csv('data.csv', usecols=['col1', 'col2'])

# 使用Parquet格式（更快、更小）
df.to_parquet('data.parquet', compression='snappy')
df = pd.read_parquet('data.parquet')
```

## 练习题

1. 读取CSV文件并查看前10行
2. 将DataFrame导出为Excel（不包含索引）
3. 从SQLite数据库读取数据
4. 合并多个CSV文件

---

**下一节：** [数据选择与索引](03-数据选择与索引.md)
