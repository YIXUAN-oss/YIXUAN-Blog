import{_ as p,c as t,d as l,e as s,f as a,b as o,w as i,r as c,o as u}from"./app-I6OnLCmc.js";const r={};function d(k,n){const e=c("RouteLink");return u(),t("div",null,[n[3]||(n[3]=l(`<h1 id="transformer" tabindex="-1"><a class="header-anchor" href="#transformer"><span>Transformer</span></a></h1><blockquote><p>掌握Transformer架构和预训练模型</p></blockquote><h2 id="📚-学习目标" tabindex="-1"><a class="header-anchor" href="#📚-学习目标"><span>📚 学习目标</span></a></h2><ul><li>理解Attention机制</li><li>掌握Transformer架构</li><li>学会使用BERT</li><li>了解GPT模型</li></ul><h2 id="_1-self-attention" tabindex="-1"><a class="header-anchor" href="#_1-self-attention"><span>1. Self-Attention</span></a></h2><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">import</span> torch</span>
<span class="line"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn</span>
<span class="line"><span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F</span>
<span class="line"></span>
<span class="line"><span class="token keyword">class</span> <span class="token class-name">SelfAttention</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> embed_dim<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token builtin">super</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">        self<span class="token punctuation">.</span>embed_dim <span class="token operator">=</span> embed_dim</span>
<span class="line">        self<span class="token punctuation">.</span>query <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>embed_dim<span class="token punctuation">,</span> embed_dim<span class="token punctuation">)</span></span>
<span class="line">        self<span class="token punctuation">.</span>key <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>embed_dim<span class="token punctuation">,</span> embed_dim<span class="token punctuation">)</span></span>
<span class="line">        self<span class="token punctuation">.</span>value <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>embed_dim<span class="token punctuation">,</span> embed_dim<span class="token punctuation">)</span></span>
<span class="line">    </span>
<span class="line">    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">        <span class="token comment"># x: (batch, seq_len, embed_dim)</span></span>
<span class="line">        Q <span class="token operator">=</span> self<span class="token punctuation">.</span>query<span class="token punctuation">(</span>x<span class="token punctuation">)</span></span>
<span class="line">        K <span class="token operator">=</span> self<span class="token punctuation">.</span>key<span class="token punctuation">(</span>x<span class="token punctuation">)</span></span>
<span class="line">        V <span class="token operator">=</span> self<span class="token punctuation">.</span>value<span class="token punctuation">(</span>x<span class="token punctuation">)</span></span>
<span class="line">        </span>
<span class="line">        <span class="token comment"># 计算注意力分数</span></span>
<span class="line">        scores <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>Q<span class="token punctuation">,</span> K<span class="token punctuation">.</span>transpose<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">2</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token operator">/</span> <span class="token punctuation">(</span>self<span class="token punctuation">.</span>embed_dim <span class="token operator">**</span> <span class="token number">0.5</span><span class="token punctuation">)</span></span>
<span class="line">        attention_weights <span class="token operator">=</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>scores<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span></span>
<span class="line">        </span>
<span class="line">        <span class="token comment"># 加权求和</span></span>
<span class="line">        out <span class="token operator">=</span> torch<span class="token punctuation">.</span>matmul<span class="token punctuation">(</span>attention_weights<span class="token punctuation">,</span> V<span class="token punctuation">)</span></span>
<span class="line">        <span class="token keyword">return</span> out</span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_2-使用-bert" tabindex="-1"><a class="header-anchor" href="#_2-使用-bert"><span>2. 使用 BERT</span></a></h2><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> BertTokenizer<span class="token punctuation">,</span> BertModel</span>
<span class="line"></span>
<span class="line"><span class="token comment"># 加载预训练模型</span></span>
<span class="line">tokenizer <span class="token operator">=</span> BertTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">&#39;bert-base-chinese&#39;</span><span class="token punctuation">)</span></span>
<span class="line">model <span class="token operator">=</span> BertModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">&#39;bert-base-chinese&#39;</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 编码文本</span></span>
<span class="line">text <span class="token operator">=</span> <span class="token string">&quot;自然语言处理很有趣&quot;</span></span>
<span class="line">inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>text<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">&#39;pt&#39;</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 获取编码</span></span>
<span class="line">outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">)</span></span>
<span class="line">last_hidden_states <span class="token operator">=</span> outputs<span class="token punctuation">.</span>last_hidden_state</span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>last_hidden_states<span class="token punctuation">.</span>shape<span class="token punctuation">)</span>  <span class="token comment"># (1, seq_len, 768)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_3-bert-文本分类" tabindex="-1"><a class="header-anchor" href="#_3-bert-文本分类"><span>3. BERT 文本分类</span></a></h2><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> BertForSequenceClassification<span class="token punctuation">,</span> AdamW</span>
<span class="line"></span>
<span class="line"><span class="token comment"># 加载分类模型</span></span>
<span class="line">model <span class="token operator">=</span> BertForSequenceClassification<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span></span>
<span class="line">    <span class="token string">&#39;bert-base-chinese&#39;</span><span class="token punctuation">,</span></span>
<span class="line">    num_labels<span class="token operator">=</span><span class="token number">2</span></span>
<span class="line"><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 训练</span></span>
<span class="line">optimizer <span class="token operator">=</span> AdamW<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">2e-5</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">)</span><span class="token punctuation">:</span></span>
<span class="line">    <span class="token keyword">for</span> batch <span class="token keyword">in</span> train_loader<span class="token punctuation">:</span></span>
<span class="line">        inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>batch<span class="token punctuation">[</span><span class="token string">&#39;text&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> </span>
<span class="line">                          truncation<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">&#39;pt&#39;</span><span class="token punctuation">)</span></span>
<span class="line">        labels <span class="token operator">=</span> batch<span class="token punctuation">[</span><span class="token string">&#39;labels&#39;</span><span class="token punctuation">]</span></span>
<span class="line">        </span>
<span class="line">        outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">,</span> labels<span class="token operator">=</span>labels<span class="token punctuation">)</span></span>
<span class="line">        loss <span class="token operator">=</span> outputs<span class="token punctuation">.</span>loss</span>
<span class="line">        </span>
<span class="line">        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line">        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_4-使用-gpt" tabindex="-1"><a class="header-anchor" href="#_4-使用-gpt"><span>4. 使用 GPT</span></a></h2><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> GPT2LMHeadModel<span class="token punctuation">,</span> GPT2Tokenizer</span>
<span class="line"></span>
<span class="line"><span class="token comment"># 加载GPT-2</span></span>
<span class="line">tokenizer <span class="token operator">=</span> GPT2Tokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">&#39;gpt2&#39;</span><span class="token punctuation">)</span></span>
<span class="line">model <span class="token operator">=</span> GPT2LMHeadModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">&#39;gpt2&#39;</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 生成文本</span></span>
<span class="line">input_text <span class="token operator">=</span> <span class="token string">&quot;Once upon a time&quot;</span></span>
<span class="line">input_ids <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>encode<span class="token punctuation">(</span>input_text<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">&#39;pt&#39;</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 生成</span></span>
<span class="line">output <span class="token operator">=</span> model<span class="token punctuation">.</span>generate<span class="token punctuation">(</span></span>
<span class="line">    input_ids<span class="token punctuation">,</span></span>
<span class="line">    max_length<span class="token operator">=</span><span class="token number">50</span><span class="token punctuation">,</span></span>
<span class="line">    num_return_sequences<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span></span>
<span class="line">    no_repeat_ngram_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span></span>
<span class="line">    temperature<span class="token operator">=</span><span class="token number">0.7</span></span>
<span class="line"><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line">generated_text <span class="token operator">=</span> tokenizer<span class="token punctuation">.</span>decode<span class="token punctuation">(</span>output<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">,</span> skip_special_tokens<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span></span>
<span class="line"><span class="token keyword">print</span><span class="token punctuation">(</span>generated_text<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="_5-中文预训练模型" tabindex="-1"><a class="header-anchor" href="#_5-中文预训练模型"><span>5. 中文预训练模型</span></a></h2><div class="language-python line-numbers-mode" data-highlighter="prismjs" data-ext="py" data-title="py"><pre><code><span class="line"><span class="token comment"># 使用Chinese-BERT</span></span>
<span class="line"><span class="token keyword">from</span> transformers <span class="token keyword">import</span> AutoTokenizer<span class="token punctuation">,</span> AutoModel</span>
<span class="line"></span>
<span class="line">tokenizer <span class="token operator">=</span> AutoTokenizer<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">&quot;hfl/chinese-bert-wwm-ext&quot;</span><span class="token punctuation">)</span></span>
<span class="line">model <span class="token operator">=</span> AutoModel<span class="token punctuation">.</span>from_pretrained<span class="token punctuation">(</span><span class="token string">&quot;hfl/chinese-bert-wwm-ext&quot;</span><span class="token punctuation">)</span></span>
<span class="line"></span>
<span class="line"><span class="token comment"># 编码</span></span>
<span class="line">text <span class="token operator">=</span> <span class="token string">&quot;今天天气很好&quot;</span></span>
<span class="line">inputs <span class="token operator">=</span> tokenizer<span class="token punctuation">(</span>text<span class="token punctuation">,</span> return_tensors<span class="token operator">=</span><span class="token string">&quot;pt&quot;</span><span class="token punctuation">)</span></span>
<span class="line">outputs <span class="token operator">=</span> model<span class="token punctuation">(</span><span class="token operator">**</span>inputs<span class="token punctuation">)</span></span>
<span class="line"></span></code></pre><div class="line-numbers" aria-hidden="true" style="counter-reset:line-number 0;"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><hr>`,15)),s("p",null,[n[1]||(n[1]=s("strong",null,"下一节：",-1)),n[2]||(n[2]=a()),o(e,{to:"/tutorials/python-ai/nlp/11-%E6%96%87%E6%9C%AC%E7%94%9F%E6%88%90.html"},{default:i(()=>[...n[0]||(n[0]=[a("文本生成",-1)])]),_:1})])])}const v=p(r,[["render",d]]),b=JSON.parse('{"path":"/tutorials/python-ai/nlp/10-Transformer.html","title":"Transformer","lang":"zh-CN","frontmatter":{"title":"Transformer"},"headers":[{"level":2,"title":"📚 学习目标","slug":"📚-学习目标","link":"#📚-学习目标","children":[]},{"level":2,"title":"1. Self-Attention","slug":"_1-self-attention","link":"#_1-self-attention","children":[]},{"level":2,"title":"2. 使用 BERT","slug":"_2-使用-bert","link":"#_2-使用-bert","children":[]},{"level":2,"title":"3. BERT 文本分类","slug":"_3-bert-文本分类","link":"#_3-bert-文本分类","children":[]},{"level":2,"title":"4. 使用 GPT","slug":"_4-使用-gpt","link":"#_4-使用-gpt","children":[]},{"level":2,"title":"5. 中文预训练模型","slug":"_5-中文预训练模型","link":"#_5-中文预训练模型","children":[]}],"git":{"createdTime":1761052725000,"updatedTime":1761052725000,"contributors":[{"name":"YIXUAN","email":"byyi.xuan@outlook.com","commits":1}]},"filePathRelative":"tutorials/python-ai/nlp/10-Transformer.md"}');export{v as comp,b as data};
